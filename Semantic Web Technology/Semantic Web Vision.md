Aim:
To provide information in a structured way to enable it to be processed automatically by machines

1. Combine structured data and inferencing (by [[Reasoners]]) to yield info not explicitly stated
2. Deal with problems of non-semantic (e.g. [[HTML]]-based) Web
	e.g. Contemporary search engines are fast but don't produce relevant data
	
This can be done by using [[URI]]s

Pre-requisites for semantic web:
1. All objects unique identified
2. Unified system for conveying and interpreting meaning


Semantic interoperability
 - refers to the same variable used across tools
 - e.g. same variable used in Excel and MATLAB
 - in all tools, the same entity is tagged in the [[Knowledge Graph]]
 - so can act as a SSOT for simulation modules


Currently: Search engines use Natural Language Processing (NLP) - to try extract meaning of information
Vision:	don't need to use NLP to extract information from implicit natural language - do explicit semantic derivation of information from the data		

Fact-Retrieval:
 - e.g. Wolfram Alpha (huge [[Knowledge Graph|knowledge base]] of facts)
 - fact retrieval search engine
 - fact retrieval serach engine is asking in natural lanaguage and receiving an answer in natural language (i.e. not a document, like in document retrieval)

Exploratory Search:
 - not used so much now
 - navigating the links in the graph to jump between nodes
 - e.g. clicking between pages in Wikipedia


Information exchange layer - translates semantic data (e.g. based on [[RDF]]) into a markup language (e.g. [[HTML]])

e.g. SPARQL
 - "look for all soccer players that have scored more than 10 goals as a member of a national team"
 - searches the knowledge graph - e.g. [[DBPedia]]
 - but need to format query very strictly - can interret question ambiguously				



References
[[Youtube - Semantic Web Technologies (L1)]]
[[Youtube - Semantic Web Technologies (L2)]]
[[Youtube2011 - The Semantic Web-An Overview]]
